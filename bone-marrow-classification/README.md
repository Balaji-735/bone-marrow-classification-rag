# Explainable Deep Learning for Multi-Class Bone Marrow Cell Type Classification

A comprehensive end-to-end Python project for classifying bone marrow cell images using Vision Transformers (ViT) with explainable AI (XAI) and RAG-based evidence explanations.

## ğŸ¯ Project Overview

This system implements an explainable deep learning approach for multi-class bone marrow cell type classification, supporting the **UN Sustainable Development Goal 3: Good Health and Well-being** by providing AI-assisted diagnostic support for hematologic analysis.

### Key Features

- **Vision Transformer (ViT) Classifier**: State-of-the-art deep learning model for cell classification
- **7 Cell Types**: BLA (Blast), EOS (Eosinophil), LYT (Lymphocyte), MON (Monocyte), NGS (Neutrophil), NIF (Immature Neutrophil), PMO (Promyelocyte)
- **Explainable AI (XAI)**:
  - Grad-CAM heatmaps showing which image regions influence predictions
  - ViT attention maps visualizing model focus areas
- **Uncertainty Estimation**: Monte Carlo Dropout for quantifying prediction confidence
- **RAG Integration**: Retrieval-Augmented Generation for evidence-backed clinical explanations
- **Classical ML Baselines**: SVM, Random Forest, and XGBoost for comparison
- **Interactive Dashboard**: Streamlit web interface for pathologists

## ğŸ“š Dataset

The model is trained on the [Bone Marrow Cell Classification Dataset](https://www.kaggle.com/datasets/donajui/bone-marrow-cell-classification) from Kaggle.

### Dataset Structure

After downloading and extracting the dataset, organize it as follows:

```
data/
â””â”€â”€ raw/
    â”œâ”€â”€ BLA/
    â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â”œâ”€â”€ image2.jpg
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ EOS/
    â”œâ”€â”€ LYT/
    â”œâ”€â”€ MON/
    â”œâ”€â”€ NGS/
    â”œâ”€â”€ NIF/
    â””â”€â”€ PMO/
```

## ğŸš€ Installation

### 1. Clone or Download the Project

```bash
cd bone-marrow-classification
```

### 2. Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Download Dataset

1. Download the dataset from [Kaggle](https://www.kaggle.com/datasets/donajui/bone-marrow-cell-classification)
2. Extract and organize images into class folders as shown above
3. Place the organized dataset in `data/raw/`

## ğŸ“– Usage

### Training the Model

Train the Vision Transformer model:

```bash
python main.py train
```

With custom parameters:

```bash
python main.py train --epochs 100 --lr 0.0001
```

### Evaluation

Evaluate the trained model on the test set:

```bash
python main.py eval
```

This will:
- Compute classification metrics (accuracy, precision, recall, F1)
- Generate confusion matrix
- Create ROC curves
- Save all results to `results/`

### Classical ML Baselines

Train classical ML baselines (SVM, Random Forest, XGBoost):

```bash
python main.py baselines
```

### Generate Explanations

Generate sample Grad-CAM and attention visualizations:

```bash
python main.py explain
```

With custom number of samples:

```bash
python main.py explain --num_samples 10
```

### RAG Demo

Generate sample RAG explanations for each cell type:

```bash
python main.py rag_demo
```

### Launch Dashboard

Start the Streamlit dashboard:

```bash
streamlit run dashboard/app.py
```

The dashboard provides:
- **Predict Page**: Upload images, get predictions with confidence/uncertainty, view visual explanations (Grad-CAM, attention maps), and read RAG-generated clinical explanations
- **Model Performance Page**: View classification metrics, confusion matrix, and ROC curves
- **About Page**: Project information and documentation

## ğŸ“ Project Structure

```
bone-marrow-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Downloaded Kaggle dataset (user places here)
â”‚   â”œâ”€â”€ processed/                    # (optional) processed images
â”‚   â””â”€â”€ splits/                       # train/val/test index info
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vit_model_best.pth           # saved trained ViT model
â”‚   â”œâ”€â”€ svm_model.pkl
â”‚   â”œâ”€â”€ rf_model.pkl
â”‚   â””â”€â”€ xgb_model.pkl                # optional
â”‚
â”œâ”€â”€ rag_framework/
â”‚   â”œâ”€â”€ rag_model.py                 # RAG pipeline wrapper
â”‚   â”œâ”€â”€ knowledge_base/
â”‚   â”‚   â””â”€â”€ hematology_knowledge.csv # knowledge base
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                    # paths, hyperparameters, constants
â”‚   â”œâ”€â”€ data_preprocessing.py        # dataset + transforms + dataloaders
â”‚   â”œâ”€â”€ model_training.py            # ViT training & validation loop
â”‚   â”œâ”€â”€ test_inference.py            # test evaluation + probability outputs
â”‚   â”œâ”€â”€ uncertainty_estimation.py    # Monte Carlo Dropout-based uncertainty
â”‚   â”œâ”€â”€ explainability.py            # Grad-CAM + ViT attention extraction
â”‚   â”œâ”€â”€ classical_ml_baseline.py     # SVM / RF / XGBoost on handcrafted features
â”‚   â”œâ”€â”€ evaluation_metrics.py        # confusion matrix, ROC, classification report
â”‚   â”œâ”€â”€ rag_integration.py           # glue between classifier prediction and RAG
â”‚   â””â”€â”€ utils.py                     # shared helpers (seeding, logging, etc.)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                 # dataset exploration (optional)
â”‚   â”œâ”€â”€ 02_train_vit.ipynb           # optional notebook wrapper for training
â”‚   â””â”€â”€ 03_explainability_demo.ipynb # optional visualization demo
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                       # Streamlit app
â”‚   â””â”€â”€ assets/                      # optional images/css
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ classification_metrics.json
â”‚   â””â”€â”€ visualizations/
â”‚       â”œâ”€â”€ class_distribution.png
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â”œâ”€â”€ roc_curves.png
â”‚       â”œâ”€â”€ sample_gradcam.png
â”‚       â””â”€â”€ sample_attention.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                          # orchestration entrypoint
```

## ğŸ”¬ Technical Details

### Model Architecture

- **Backbone**: Vision Transformer (ViT-Base, patch size 16, 224Ã—224 input)
- **Pretrained**: ImageNet pretrained weights
- **Classifier Head**: Custom head with LayerNorm, Dropout, and Linear layer
- **Output**: 7-class softmax probabilities

### Training Configuration

- **Batch Size**: 32
- **Learning Rate**: 1e-4 (AdamW optimizer)
- **Epochs**: 50 (with early stopping)
- **Data Augmentation**: Random horizontal flip, rotation, color jitter
- **Loss Function**: CrossEntropyLoss with label smoothing (0.1)

### Explainability Methods

1. **Grad-CAM**: Gradient-weighted Class Activation Mapping
   - Highlights image regions that influence the prediction
   - Uses gradients from the last transformer block

2. **ViT Attention Maps**: 
   - Visualizes attention weights from transformer blocks
   - Shows which image patches the model focuses on

### Uncertainty Estimation

- **Method**: Monte Carlo Dropout
- **Samples**: 30 stochastic forward passes
- **Metrics**: 
  - Epistemic uncertainty (model uncertainty)
  - Aleatoric uncertainty (data ambiguity)
  - Total uncertainty

### RAG Framework

- **Knowledge Base**: CSV-based hematology knowledge base
- **Retrieval**: Keyword-based similarity search
- **Generation**: Templated explanations with retrieved evidence
- **Sources**: Clinical references for each explanation

## ğŸ“Š Evaluation Metrics

The system computes:
- Overall accuracy
- Per-class precision, recall, F1-score
- Confusion matrix
- ROC curves and AUC scores
- Class distribution

## âš ï¸ Medical Disclaimer

**This system is designed for research and educational purposes only.** It should not be used as the sole basis for clinical diagnosis. All predictions should be reviewed by qualified medical professionals.

## ğŸ“– References

- **Vision Transformer**: Dosovitskiy et al., "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", NeurIPS 2020
- **Grad-CAM**: Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization", ICCV 2017
- **RAG**: Lewis et al., "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", NeurIPS 2020
- **Monte Carlo Dropout**: Gal & Ghahramani, "Dropout as a Bayesian Approximation", ICML 2016

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

## ğŸ“„ License

This project is provided for educational and research purposes.

## ğŸ‘¥ Authors

Developed for medical imaging research and explainable AI applications in hematology.

---

**For questions or issues, please open an issue on the project repository.**







